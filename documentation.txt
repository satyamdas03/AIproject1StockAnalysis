steps:
1) setting up the environment 
    --> we are going to setup our pyproject.toml this is basically going to turn all the requirements of our project into code
    so that we can just run our install script basically to package and build all the necessary dependencies to run our python application
    
    --> we are gonna have to install poetry  ==> pipx install poetry
    --> before installing poetry, we are gonna need to install pipx ==> use : py -m pip install --user pipx
    --> we have to create our own pyproject.toml file
        --> there are 2 key components that needed to be set up first one is "tool.poetry" in which we need to define the core components such as the "name", "description"
        --> the other one is the dependencies where we are going to specifically call out which package conversions we need to set up crew
        all of the necessary stuff is written in the project.toml file
        -->tool.pyright is going to allow us to check python codes for type errors
        -->tool.ruff is going to check for errors and also styling issues
        -->build-system is going to poetry version 

2) next step is to open up the terminal and do "poetry install --no-root"

3) poetry env list --> to check the currently used Python version for your Poetry environment with

4) poetry shell --> enter into the poetry environment  
        # after this we will have a python environment in which we can work in
    
After this we can start working on the agents


Cheat Sheet to Make a Good Agent
    Begin with the end in mind: Identify the specific outcome your tasks are aiming to achieve.
    Break down the outcome into actionable tasks: Assign each task to the appropriate agent.
    Ensure the tasks are descriptive: Provide clear instructions and expected deliverables.
Goal:
    Develop a comprehensive stock analysis report that includes trend analysis, predictions, and investment recommendations.
Captain/Manager/Boss:
    Expert Stock Analyst
Employees/Experts to Hire:
    Data Collection Specialist
Data Cleaning Expert
    Data Visualization Expert
Prediction Model Specialist
    Investment Advisor
Notes:
    Agents should be results-driven and have a clear goal in mind.
Role: Their job title.
Goals: Should be actionable.
Backstory: Should be their resume.
Agents and Their Responsibilities:
    Expert Stock Analyst

Role: Oversees the entire stock analysis project.
Goal: Ensure the final report is accurate, comprehensive, and actionable.
Backstory: Experienced stock analyst with a background in financial markets and data analysis.
Data Collection Specialist

Role: Collects relevant stock data from various sources.
Goal: Gather comprehensive and accurate data for analysis.
Backstory: Proficient in web scraping, API usage, and data gathering techniques.
Data Cleaning Expert

Role: Cleans and preprocesses the collected data.
Goal: Ensure the data is clean, consistent, and ready for analysis.
Backstory: Experienced in data cleaning and preprocessing with strong attention to detail.
Data Visualization Expert

Role: Creates visual representations of the data.
Goal: Develop insightful charts and graphs to visualize trends and patterns.
Backstory: Skilled in data visualization tools like Matplotlib, Seaborn, and Plotly.
Prediction Model Specialist

Role: Builds and trains predictive models.
Goal: Develop accurate models to predict stock trends and prices.
Backstory: Proficient in machine learning and statistical modeling techniques.
Investment Advisor

Role: Provides investment recommendations based on analysis.
Goal: Offer actionable investment advice to maximize returns.
Backstory: Experienced financial advisor with a deep understanding of stock markets and investment strategies.
Tools for the Agents
Folder: tools
search_tools.py: Implements tools for searching and retrieving data from various sources.
calculator_tools.py: Implements tools for performing financial calculations and statistical analysis.


======================================================

QUERIES TO BE ANSWERED:

1. Which model is this project using to train and all like ANN, or CNN or something else?
The project is not using traditional machine learning models like ANN (Artificial Neural Networks) or CNN (Convolutional Neural Networks). Instead, it leverages pre-existing AI tools and APIs to perform various tasks such as web scraping, financial calculations, and document analysis.

2. Which model would be optimal to train the model and get the output and why?
Given the nature of this project, which involves financial data analysis, market trend interpretation, and investment recommendations, a traditional machine learning model is not necessarily optimal. Instead, using pre-trained models and APIs like those provided by LangChain, SEC API, and other specific tools is more effective. These tools are designed to handle specific tasks like data scraping, document parsing, and embeddings for document similarity.

If you were to incorporate a custom model, you might consider:

Natural Language Processing (NLP) models for text analysis and summarization.
Time Series Analysis models for financial trend prediction.
Ensemble Models that combine multiple approaches for more robust predictions.
3. Is this project using an LLM (Large Language Model)?
Yes, the project utilizes LLMs through the LangChain library and specific tools like the YahooFinanceNewsTool and the custom agents defined in stock_analysis_agents.py. These tools and agents use pre-trained language models to perform tasks like summarizing web content, searching the internet, and analyzing financial documents.

4. Can LLM be added to the project title of this project name?
Yes, given that the project heavily relies on language models for various tasks, it is appropriate to include LLM in the project title. A possible name could be:

"LLM-Powered Financial Analysis and Investment Advisor"

This title reflects the use of Large Language Models in the project's functionality.

Summary of the Project's Approach:
The project leverages various pre-trained tools and APIs to perform its tasks, without the need for traditional machine learning models like ANN or CNN. The integration of LLMs through LangChain and specific financial analysis tools forms the core of the project's analytical capabilities.
